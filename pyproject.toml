[project]
name = "PyALM"
version = "0.1.0"
authors = [
  { name="Finn Schwall", email="finn.schwall@isob.fraunhofer.de" },
]
description = "Python abstraction layer for large language models"
readme = "README.md"
requires-python = ">=3.8"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: Apache 2",
    "Operating System :: OS Independent",
]

dependencies = [
    "pylot@git+https://github.com/finnschwall/PyLoT",
    "psutil~=5.9.5",
#    "tiktoken~=0.5.1",
#    "tqdm~=4.66.1",
    "numpy",
    "docstring_parser==0.15",
#    "openai",
    "pyyaml",
#    "aleph_alpha_client",
#    "llama-cpp-python",
]
[project.optional-dependencies]
openai = [
    "tiktoken~=0.5.1",
     "openai"
]
aleph_alpha = ["aleph_alpha_client"]
llama = ["llama-cpp-python"]
full = ["tiktoken~=0.5.1",
     "openai","aleph_alpha_client","llama-cpp-python"]



[project.urls]
"Homepage" = "https://github.com/finnschwall/PyALM"

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"
