Search.setIndex({"docnames": ["index", "modules/module_aleph_alpha", "modules/module_alm", "modules/module_llama", "modules/module_openai", "modules/module_resources"], "filenames": ["index.md", "modules/module_aleph_alpha.md", "modules/module_alm.md", "modules/module_llama.md", "modules/module_openai.md", "modules/module_resources.md"], "titles": ["Welcome to PyAML\u2019s documentation!", "Aleph Alpha", "Core", "Local LlaMa models", "OpenAI", "Helpers"], "terms": {"core": 0, "alm": [0, 2], "conversationrol": [0, 2], "functionformat": [0, 2], "parsestatu": [0, 2], "_get_enum_valu": [0, 2], "local": 0, "llama": 0, "model": 0, "_ban_eos_logits_processor": [0, 3], "_build_llama": [0, 3], "_log_callback": [0, 3], "openai": 0, "aleph": 0, "alpha": 0, "alephalpha": [0, 1], "helper": 0, "get_resource_diff": [0, 5], "get_resource_info": [0, 5], "wip": [1, 2, 3, 4, 5], "class": [1, 2, 3, 4], "pyalm": [1, 2, 3, 4, 5], "model_path_or_nam": [1, 2, 4], "aleph_alpha_kei": 1, "none": [1, 2, 3, 4], "verbos": [1, 2, 3, 4], "0": [1, 2, 3, 4], "n_ctx": [1, 2, 3, 4], "2048": [1, 2, 3, 4], "kwarg": [1, 2, 3, 4], "available_model": [1, 4], "lumin": 1, "suprem": 1, "base": 1, "extend": 1, "control": 1, "build_prompt": [1, 2, 3, 4], "preserve_flow": [1, 2, 3], "fals": [1, 2, 3, 4], "create_native_complet": [1, 3, 4], "text": [1, 2, 3, 4], "max_token": [1, 3, 4], "256": [1, 3, 4], "stop": [1, 2, 3, 4], "token_prob_delta": [1, 2, 3, 4], "token_prob_ab": [1, 2, 3, 4], "log_prob": [1, 3, 4], "keep_dict": [1, 4], "create_native_gener": [1, 2, 3, 4], "detoken": [1, 3], "tok": [1, 3], "get_n_token": [1, 2, 3, 4], "get_remaining_token": 1, "static": 1, "image_from_sourc": 1, "sourc": 1, "multimodal_complet": 1, "prompt_list": 1, "price": [1, 4], "ba": 1, "03": [1, 4], "0375": 1, "045": 1, "05625": 1, "175": 1, "21875": 1, "pricing_factor": 1, "complet": 1, "input": [1, 4], "1": [1, 2, 3], "output": [1, 4], "summar": 1, "3": [1, 4], "pricing_img": 1, "03024": 1, "04536": 1, "pricing_meta": [1, 4], "currenc": [1, 4], "credit": 1, "token_unit": [1, 4], "1000": [1, 4], "2": 1, "path_to_docx": 1, "token": [1, 2, 3, 4], "tokenize_as_str": [1, 2, 3, 4], "_extract_and_handle_funct": 2, "call_funct": 2, "true": [2, 3], "_repl": 2, "match": 2, "_replace_symbol": 2, "add_tracker_entri": 2, "role": 2, "content": 2, "meta": 2, "function_cal": 2, "context": 2, "feedback": 2, "sentiment": 2, "add_kei": 2, "adopt_from_alm": 2, "other": 2, "type": 2, "abstract": 2, "build_prompt_as_str": 2, "new_lines_per_rol": 2, "new_lines_afer_rol": 2, "block_gen_prefix": 2, "create_complet": 2, "text_obj": 2, "enable_function_cal": 2, "chat": 2, "handle_funct": 2, "create_completion_gener": 2, "return_function_cal": 2, "endless": [2, 3], "arg": 2, "load_histori": 2, "path": [2, 3], "register_funct": 2, "function": 2, "reset_track": 2, "save_histori": 2, "set_system_messag": 2, "msg": 2, "prepend_function_support": 2, "valu": 2, "an": 2, "enumer": 2, "assist": 2, "user": 2, "json": 2, "model_specif": 2, "pydoc": 2, "no_func_sequence_found": 2, "parsed_dict_return": 2, "parsed_executed_err": 2, "parsed_executed_ok": 2, "unparseable_func_found": 2, "input_valu": 2, "enum_typ": 2, "model_path": 3, "n_thread": 3, "n_gpu_lay": 3, "quantize_format": 3, "auto": 3, "is_70b": 3, "disable_log_hook": 3, "disable_model_load": 3, "512": 3, "stream": 3, "load_state_from_disk": 3, "filenam": 3, "restore_ctx_from_disk": 3, "save_ctx_to_disk": 3, "prompt": 3, "save_state_to_disk": 3, "setup_backend": 3, "eos_token": 3, "input_id": 3, "logit": 3, "_llama": 3, "level": 3, "int": 3, "str": 3, "user_data": 3, "c_void_p": 3, "openai_kei": 4, "_extract_message_from_gener": 4, "gen": 4, "gpt": 4, "5": 4, "turbo": 4, "16k": 4, "4": 4, "conv_histori": 4, "system_msg": 4, "0015": 4, "002": 4, "003": 4, "004": 4, "06": 4, "resourc": 5, "res_a": 5, "res_b": 5}, "objects": {"pyalm": [[1, 0, 0, "-", "alephalpha"], [2, 0, 0, "-", "alm"], [3, 0, 0, "-", "llama"], [4, 0, 0, "-", "openai"], [5, 0, 0, "-", "resources"]], "pyalm.alephalpha": [[1, 1, 1, "", "AlephAlpha"]], "pyalm.alephalpha.AlephAlpha": [[1, 2, 1, "", "available_models"], [1, 3, 1, "", "build_prompt"], [1, 3, 1, "", "create_native_completion"], [1, 3, 1, "", "create_native_generator"], [1, 3, 1, "", "detokenize"], [1, 3, 1, "", "get_n_tokens"], [1, 3, 1, "", "get_remaining_tokens"], [1, 3, 1, "", "image_from_source"], [1, 3, 1, "", "multimodal_completion"], [1, 2, 1, "", "pricing"], [1, 2, 1, "", "pricing_factors"], [1, 2, 1, "", "pricing_img"], [1, 2, 1, "", "pricing_meta"], [1, 3, 1, "", "summarize"], [1, 3, 1, "", "tokenize"], [1, 3, 1, "", "tokenize_as_str"]], "pyalm.alm": [[2, 1, 1, "", "ALM"], [2, 1, 1, "", "ConversationRoles"], [2, 1, 1, "", "FunctionFormat"], [2, 1, 1, "", "ParseStatus"], [2, 4, 1, "", "_get_enum_value"]], "pyalm.alm.ALM": [[2, 3, 1, "", "_extract_and_handle_functions"], [2, 3, 1, "", "_repl"], [2, 3, 1, "", "_replace_symbols"], [2, 3, 1, "", "add_tracker_entry"], [2, 3, 1, "", "adopt_from_alm"], [2, 3, 1, "", "build_prompt"], [2, 3, 1, "", "build_prompt_as_str"], [2, 3, 1, "", "create_completion"], [2, 3, 1, "", "create_completion_generator"], [2, 3, 1, "", "create_native_generator"], [2, 3, 1, "", "get_n_tokens"], [2, 3, 1, "", "load_history"], [2, 3, 1, "", "register_functions"], [2, 3, 1, "", "reset_tracker"], [2, 3, 1, "", "save_history"], [2, 3, 1, "", "set_system_message"], [2, 3, 1, "", "tokenize"], [2, 3, 1, "", "tokenize_as_str"]], "pyalm.alm.ConversationRoles": [[2, 2, 1, "", "ASSISTANT"], [2, 2, 1, "", "USER"]], "pyalm.alm.FunctionFormat": [[2, 2, 1, "", "JSON"], [2, 2, 1, "", "MODEL_SPECIFIC"], [2, 2, 1, "", "PYDOC"]], "pyalm.alm.ParseStatus": [[2, 2, 1, "", "NO_FUNC_SEQUENCE_FOUND"], [2, 2, 1, "", "PARSED_DICT_RETURN"], [2, 2, 1, "", "PARSED_EXECUTED_ERR"], [2, 2, 1, "", "PARSED_EXECUTED_OK"], [2, 2, 1, "", "UNPARSEABLE_FUNC_FOUND"]], "pyalm.llama": [[3, 1, 1, "", "LLaMa"], [3, 4, 1, "", "_ban_eos_logits_processor"], [3, 4, 1, "", "_build_llama"], [3, 4, 1, "", "_log_callback"]], "pyalm.llama.LLaMa": [[3, 3, 1, "", "build_prompt"], [3, 3, 1, "", "create_native_completion"], [3, 3, 1, "", "create_native_generator"], [3, 3, 1, "", "detokenize"], [3, 3, 1, "", "get_n_tokens"], [3, 3, 1, "", "load_state_from_disk"], [3, 3, 1, "", "restore_ctx_from_disk"], [3, 3, 1, "", "save_ctx_to_disk"], [3, 3, 1, "", "save_state_to_disk"], [3, 3, 1, "", "setup_backend"], [3, 3, 1, "", "tokenize"], [3, 3, 1, "", "tokenize_as_str"]], "pyalm.openai": [[4, 1, 1, "", "OpenAI"]], "pyalm.openai.OpenAI": [[4, 3, 1, "", "_extract_message_from_generator"], [4, 2, 1, "", "available_models"], [4, 3, 1, "", "build_prompt"], [4, 3, 1, "", "create_native_completion"], [4, 3, 1, "", "create_native_generator"], [4, 3, 1, "", "get_n_tokens"], [4, 2, 1, "", "pricing"], [4, 2, 1, "", "pricing_meta"], [4, 3, 1, "", "tokenize"], [4, 3, 1, "", "tokenize_as_str"]], "pyalm.resources": [[5, 4, 1, "", "get_resource_diff"], [5, 4, 1, "", "get_resource_info"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "pyaml": 0, "": 0, "document": 0, "full": 0, "tabl": 0, "content": 0, "aleph": 1, "alpha": 1, "core": 2, "local": 3, "llama": 3, "model": 3, "openai": 4, "helper": 5}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"Welcome to PyAML\u2019s documentation!": [[0, "welcome-to-pyaml-s-documentation"]], "Full table of contents": [[0, "full-table-of-contents"]], "Aleph Alpha": [[1, "aleph-alpha"]], "Core": [[2, "core"]], "Local LlaMa models": [[3, "local-llama-models"]], "OpenAI": [[4, "openai"]], "Helpers": [[5, "helpers"]]}, "indexentries": {"alephalpha (class in pyalm.alephalpha)": [[1, "pyalm.alephalpha.AlephAlpha"]], "available_models (pyalm.alephalpha.alephalpha attribute)": [[1, "pyalm.alephalpha.AlephAlpha.available_models"]], "build_prompt() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.build_prompt"]], "create_native_completion() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.create_native_completion"]], "create_native_generator() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.create_native_generator"]], "detokenize() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.detokenize"]], "get_n_tokens() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.get_n_tokens"]], "get_remaining_tokens() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.get_remaining_tokens"]], "image_from_source() (pyalm.alephalpha.alephalpha static method)": [[1, "pyalm.alephalpha.AlephAlpha.image_from_source"]], "module": [[1, "module-pyalm.alephalpha"], [2, "module-pyalm.alm"], [3, "module-pyalm.llama"], [4, "module-pyalm.openai"], [5, "module-pyalm.resources"]], "multimodal_completion() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.multimodal_completion"]], "pricing (pyalm.alephalpha.alephalpha attribute)": [[1, "pyalm.alephalpha.AlephAlpha.pricing"]], "pricing_factors (pyalm.alephalpha.alephalpha attribute)": [[1, "pyalm.alephalpha.AlephAlpha.pricing_factors"]], "pricing_img (pyalm.alephalpha.alephalpha attribute)": [[1, "pyalm.alephalpha.AlephAlpha.pricing_img"]], "pricing_meta (pyalm.alephalpha.alephalpha attribute)": [[1, "pyalm.alephalpha.AlephAlpha.pricing_meta"]], "pyalm.alephalpha": [[1, "module-pyalm.alephalpha"]], "summarize() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.summarize"]], "tokenize() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.tokenize"]], "tokenize_as_str() (pyalm.alephalpha.alephalpha method)": [[1, "pyalm.alephalpha.AlephAlpha.tokenize_as_str"]], "alm (class in pyalm.alm)": [[2, "pyalm.alm.ALM"]], "assistant (pyalm.alm.conversationroles attribute)": [[2, "pyalm.alm.ConversationRoles.ASSISTANT"]], "conversationroles (class in pyalm.alm)": [[2, "pyalm.alm.ConversationRoles"]], "functionformat (class in pyalm.alm)": [[2, "pyalm.alm.FunctionFormat"]], "json (pyalm.alm.functionformat attribute)": [[2, "pyalm.alm.FunctionFormat.JSON"]], "model_specific (pyalm.alm.functionformat attribute)": [[2, "pyalm.alm.FunctionFormat.MODEL_SPECIFIC"]], "no_func_sequence_found (pyalm.alm.parsestatus attribute)": [[2, "pyalm.alm.ParseStatus.NO_FUNC_SEQUENCE_FOUND"]], "parsed_dict_return (pyalm.alm.parsestatus attribute)": [[2, "pyalm.alm.ParseStatus.PARSED_DICT_RETURN"]], "parsed_executed_err (pyalm.alm.parsestatus attribute)": [[2, "pyalm.alm.ParseStatus.PARSED_EXECUTED_ERR"]], "parsed_executed_ok (pyalm.alm.parsestatus attribute)": [[2, "pyalm.alm.ParseStatus.PARSED_EXECUTED_OK"]], "pydoc (pyalm.alm.functionformat attribute)": [[2, "pyalm.alm.FunctionFormat.PYDOC"]], "parsestatus (class in pyalm.alm)": [[2, "pyalm.alm.ParseStatus"]], "unparseable_func_found (pyalm.alm.parsestatus attribute)": [[2, "pyalm.alm.ParseStatus.UNPARSEABLE_FUNC_FOUND"]], "user (pyalm.alm.conversationroles attribute)": [[2, "pyalm.alm.ConversationRoles.USER"]], "_extract_and_handle_functions() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM._extract_and_handle_functions"]], "_get_enum_value() (in module pyalm.alm)": [[2, "pyalm.alm._get_enum_value"]], "_repl() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM._repl"]], "_replace_symbols() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM._replace_symbols"]], "add_tracker_entry() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.add_tracker_entry"]], "adopt_from_alm() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.adopt_from_alm"]], "build_prompt() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.build_prompt"]], "build_prompt_as_str() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.build_prompt_as_str"]], "create_completion() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.create_completion"]], "create_completion_generator() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.create_completion_generator"]], "create_native_generator() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.create_native_generator"]], "get_n_tokens() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.get_n_tokens"]], "load_history() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.load_history"]], "pyalm.alm": [[2, "module-pyalm.alm"]], "register_functions() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.register_functions"]], "reset_tracker() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.reset_tracker"]], "save_history() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.save_history"]], "set_system_message() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.set_system_message"]], "tokenize() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.tokenize"]], "tokenize_as_str() (pyalm.alm.alm method)": [[2, "pyalm.alm.ALM.tokenize_as_str"]], "llama (class in pyalm.llama)": [[3, "pyalm.llama.LLaMa"]], "_ban_eos_logits_processor() (in module pyalm.llama)": [[3, "pyalm.llama._ban_eos_logits_processor"]], "_build_llama() (in module pyalm.llama)": [[3, "pyalm.llama._build_llama"]], "_log_callback() (in module pyalm.llama)": [[3, "pyalm.llama._log_callback"]], "build_prompt() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.build_prompt"]], "create_native_completion() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.create_native_completion"]], "create_native_generator() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.create_native_generator"]], "detokenize() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.detokenize"]], "get_n_tokens() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.get_n_tokens"]], "load_state_from_disk() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.load_state_from_disk"]], "pyalm.llama": [[3, "module-pyalm.llama"]], "restore_ctx_from_disk() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.restore_ctx_from_disk"]], "save_ctx_to_disk() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.save_ctx_to_disk"]], "save_state_to_disk() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.save_state_to_disk"]], "setup_backend() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.setup_backend"]], "tokenize() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.tokenize"]], "tokenize_as_str() (pyalm.llama.llama method)": [[3, "pyalm.llama.LLaMa.tokenize_as_str"]], "openai (class in pyalm.openai)": [[4, "pyalm.openai.OpenAI"]], "_extract_message_from_generator() (pyalm.openai.openai method)": [[4, "pyalm.openai.OpenAI._extract_message_from_generator"]], "available_models (pyalm.openai.openai attribute)": [[4, "pyalm.openai.OpenAI.available_models"]], "build_prompt() (pyalm.openai.openai method)": [[4, "pyalm.openai.OpenAI.build_prompt"]], "create_native_completion() (pyalm.openai.openai method)": [[4, "pyalm.openai.OpenAI.create_native_completion"]], "create_native_generator() (pyalm.openai.openai method)": [[4, "pyalm.openai.OpenAI.create_native_generator"]], "get_n_tokens() (pyalm.openai.openai method)": [[4, "pyalm.openai.OpenAI.get_n_tokens"]], "pricing (pyalm.openai.openai attribute)": [[4, "pyalm.openai.OpenAI.pricing"]], "pricing_meta (pyalm.openai.openai attribute)": [[4, "pyalm.openai.OpenAI.pricing_meta"]], "pyalm.openai": [[4, "module-pyalm.openai"]], "tokenize() (pyalm.openai.openai method)": [[4, "pyalm.openai.OpenAI.tokenize"]], "tokenize_as_str() (pyalm.openai.openai method)": [[4, "pyalm.openai.OpenAI.tokenize_as_str"]], "get_resource_diff() (in module pyalm.resources)": [[5, "pyalm.resources.get_resource_diff"]], "get_resource_info() (in module pyalm.resources)": [[5, "pyalm.resources.get_resource_info"]], "pyalm.resources": [[5, "module-pyalm.resources"]]}})