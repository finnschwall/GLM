# Installation
## Precompiled binaries
https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/tag/wheels


## Manual installation
Strongly recommend experience with building and C.

### Optional start
Build original library: https://github.com/ggerganov/llama.cpp
Not necessary. But gives access to the endless scripts and other stuff.
Also the only way to train LoRA from quantized model is from this fork https://github.com/xaedes/llama.cpp/tree/finetune-lora 
(as of now)

### The rest
Your on your own now. Follow this. 
https://github.com/abetlen/llama-cpp-python
Keep in mind you will need the stuff to compile i.e. cuda, make, g++ etc.